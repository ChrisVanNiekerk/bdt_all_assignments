{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages and start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd \n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, Imputer, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "spark = SparkSession.builder.appName('random_forest_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get External dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 4)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://storage.googleapis.com/bdt-spark-store/external_sources.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df_ext = spark.read.csv(\"file:///\"+SparkFiles.get(\"external_sources.csv\"), header=True, inferSchema= True)\n",
    "print((df_ext.count(), len(df_ext.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 119)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://storage.googleapis.com/bdt-spark-store/internal_data.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df_data  = spark.read.csv(\"file:///\"+SparkFiles.get(\"internal_data.csv\"), header=True, inferSchema= True)\n",
    "print((df_data.count(), len(df_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n"
     ]
    }
   ],
   "source": [
    "df_full = df_data.join(df_ext, on='SK_ID_CURR', how='inner')\n",
    "print((df_full.count(), len(df_full.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for columns required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_extract = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                  'DAYS_BIRTH', 'DAYS_EMPLOYED', 'NAME_EDUCATION_TYPE',\n",
    "                  'DAYS_ID_PUBLISH', 'CODE_GENDER', 'AMT_ANNUITY',\n",
    "                  'DAYS_REGISTRATION', 'AMT_GOODS_PRICE', 'AMT_CREDIT',\n",
    "                  'ORGANIZATION_TYPE', 'DAYS_LAST_PHONE_CHANGE',\n",
    "                  'NAME_INCOME_TYPE', 'AMT_INCOME_TOTAL', 'OWN_CAR_AGE', 'TARGET']\n",
    "df = df_full[columns_extract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['NAME_EDUCATION_TYPE', 'CODE_GENDER', 'ORGANIZATION_TYPE', 'NAME_INCOME_TYPE']\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"-index\") for column in categorical_variables]\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
    "    outputCols=[\"{0}-encoded\".format(indexer.getOutputCol()) for indexer in indexers]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=encoder.getOutputCols(),\n",
    "    outputCol=\"categorical-features\"\n",
    ")\n",
    "\n",
    "cat_var = assembler\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [encoder, assembler])\n",
    "df_oh = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (246051, 27)\n",
      "Testing data shape:  (61460, 27)\n"
     ]
    }
   ],
   "source": [
    "train, test = df_oh.randomSplit([0.8, 0.2], seed=101)\n",
    "print('Training data shape: ', (train.count(), len(train.columns)))\n",
    "print('Testing data shape: ', (test.count(), len(test.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate target variable proportions in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------------------+\n",
      "|TARGET| count|   train_proportion|\n",
      "+------+------+-------------------+\n",
      "|     1| 19861|0.08071903792303221|\n",
      "|     0|226190| 0.9192809620769677|\n",
      "+------+------+-------------------+\n",
      "\n",
      "None\n",
      "+------+-----+-------------------+\n",
      "|TARGET|count|    test_proportion|\n",
      "+------+-----+-------------------+\n",
      "|     1| 4964|0.08076797917344615|\n",
      "|     0|56496| 0.9192320208265539|\n",
      "+------+-----+-------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_prop = train.groupBy('TARGET').count()\n",
    "test_prop = test.groupBy('TARGET').count()\n",
    "print(train_prop.withColumn('train_proportion', train_prop['count'] / train.count()).show())\n",
    "print(test_prop.withColumn('test_proportion', test_prop['count'] / test.count()).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer()\n",
    "\n",
    "imputer.setInputCols(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_LAST_PHONE_CHANGE', 'OWN_CAR_AGE'])\n",
    "\n",
    "imputer.setOutputCols(['out_EXT_SOURCE_1', 'out_EXT_SOURCE_2', 'out_EXT_SOURCE_3', 'out_AMT_ANNUITY', 'out_AMT_GOODS_PRICE', 'out_DAYS_LAST_PHONE_CHANGE', 'out_OWN_CAR_AGE'])\n",
    "\n",
    "imputer.getRelativeError()\n",
    "\n",
    "imputer.setStrategy('median')\n",
    "\n",
    "model = imputer.fit(train)\n",
    "model.setInputCols(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_LAST_PHONE_CHANGE', 'OWN_CAR_AGE'])\n",
    "train_filled = model.transform(train)\n",
    "\n",
    "model = imputer.fit(test)\n",
    "model.setInputCols(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_LAST_PHONE_CHANGE', 'OWN_CAR_AGE'])\n",
    "test_filled = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_LAST_PHONE_CHANGE', 'OWN_CAR_AGE']\n",
    "train_filled_dropped = train_filled.drop(*columns_to_drop)\n",
    "test_filled_dropped = test_filled.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine categorical vector with continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION',\n",
    "                        'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'TARGET', 'out_AMT_ANNUITY',\n",
    "                        'out_DAYS_LAST_PHONE_CHANGE', 'out_EXT_SOURCE_1', 'out_OWN_CAR_AGE',\n",
    "                        'out_EXT_SOURCE_2', 'out_AMT_GOODS_PRICE', 'out_EXT_SOURCE_3']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['categorical-features', *continuous_variables], outputCol='features')\n",
    "\n",
    "con_var = assembler\n",
    "train_filled_dropped_comb = assembler.transform(train_filled_dropped)\n",
    "test_filled_dropped_comb = assembler.transform(test_filled_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cat_var.getInputCols() + con_var.getInputCols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "scaler_model = scaler.fit(train_filled_dropped_comb)\n",
    "train_final = scaler_model.transform(train_filled_dropped_comb)\n",
    "\n",
    "scaler_model = scaler.fit(test_filled_dropped_comb)\n",
    "test_final = scaler_model.transform(test_filled_dropped_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DAYS_BIRTH=-15272, DAYS_EMPLOYED=-337, NAME_EDUCATION_TYPE='Secondary / secondary special', DAYS_ID_PUBLISH=-3622, CODE_GENDER='M', DAYS_REGISTRATION=-437.0, AMT_CREDIT=263686.5, ORGANIZATION_TYPE='Business Entity Type 3', NAME_INCOME_TYPE='Working', AMT_INCOME_TOTAL=90000.0, TARGET=0, NAME_EDUCATION_TYPE-index=0.0, CODE_GENDER-index=1.0, ORGANIZATION_TYPE-index=0.0, NAME_INCOME_TYPE-index=0.0, NAME_EDUCATION_TYPE-index-encoded=SparseVector(4, {0: 1.0}), CODE_GENDER-index-encoded=SparseVector(2, {1: 1.0}), ORGANIZATION_TYPE-index-encoded=SparseVector(57, {0: 1.0}), NAME_INCOME_TYPE-index-encoded=SparseVector(7, {0: 1.0}), categorical-features=SparseVector(70, {0: 1.0, 5: 1.0, 6: 1.0, 63: 1.0}), out_AMT_ANNUITY=17298.0, out_DAYS_LAST_PHONE_CHANGE=-235.0, out_EXT_SOURCE_1=0.5051892165955818, out_OWN_CAR_AGE=9.0, out_EXT_SOURCE_2=0.5655961111797336, out_AMT_GOODS_PRICE=238500.0, out_EXT_SOURCE_3=0.5352762504724826, features=SparseVector(84, {0: 1.0, 5: 1.0, 6: 1.0, 63: 1.0, 70: -15272.0, 71: -337.0, 72: -3622.0, 73: -437.0, 74: 263686.5, 75: 90000.0, 77: 17298.0, 78: -235.0, 79: 0.5052, 80: 9.0, 81: 0.5656, 82: 238500.0, 83: 0.5353}), scaled_features=SparseVector(84, {0: 2.2039, 5: 2.1086, 6: 2.4088, 63: 2.001, 70: -3.4977, 71: -0.0024, 72: -2.3992, 73: -0.124, 74: 0.6551, 75: 0.3487, 77: 1.1924, 78: -0.2842, 79: 3.628, 80: 1.2654, 81: 2.963, 82: 0.646, 83: 3.0646}))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"TARGET\", featuresCol=\"scaled_features\", numTrees=100, seed=50, impurity='gini', )\n",
    "\n",
    "model = rf.fit(train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_final).select(\"TARGET\", \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.966743\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "# acc = evaluator.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84,[0,1,2,3,4,5,6,7,8,10,13,14,16,19,21,22,24,26,27,29,30,31,33,35,36,37,38,40,41,42,43,45,46,47,48,49,52,53,54,55,57,59,63,64,65,66,70,71,72,73,74,75,76,77,78,79,80,81,82,83],[0.0020351836887785766,0.003414022670935533,9.196298726670885e-07,5.0116962893866196e-05,0.007395942585985196,0.0016321986267239985,3.850109945755476e-05,0.0012744426132457506,0.00027373763063220723,1.1033137315551346e-05,9.587951942054302e-05,8.592478739609784e-06,1.453948570030592e-05,4.072256739968085e-06,4.965041659466955e-06,1.1469854789092493e-05,5.890521440870412e-06,4.242745928231173e-06,2.521227758916999e-07,3.4358979065826033e-07,2.2530409655537502e-05,1.2540796557951034e-05,9.742120257585452e-05,1.0204240323891398e-06,0.00043924642955036724,5.0427921942028874e-05,6.720967785087333e-05,3.970115331517087e-06,2.759677541588403e-05,1.4763708415381342e-06,2.2361965318388316e-06,9.372916092265496e-07,2.425087300563969e-06,1.4208856961908024e-06,6.398930320568998e-06,2.406870223871948e-06,6.1775825775334696e-06,5.5080624933574894e-06,8.852382766547554e-06,8.836460316818489e-07,9.718358904284375e-06,2.0916426654601105e-06,0.002004969343182612,9.473888476878526e-06,0.0011668347551431297,1.366667714616145e-05,0.0033675511101577656,0.0030336839447335923,0.00048155822398316826,0.0003848256591904112,0.0006589128651568391,0.00010727585957762963,0.9034957383379264,0.005350999221074761,0.0009605660803631441,0.015864101506125102,0.0006599426094991499,0.013909564160760328,0.005178549139476205,0.026302943294326236])\n"
     ]
    }
   ],
   "source": [
    "print(model.featureImportances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
